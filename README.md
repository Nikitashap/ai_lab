# Шапошник Никита М8О-408Б-21

Для выполнения работы были выбраны два датасета.<br /> Первый для задача классификации. Задачей является определение машин, которые скоро придут в негодное состояние.<br />
Второй для задачи регрессии - [Sleep Efficiency Dataset](https://www.kaggle.com/datasets/equilibriumm/sleep-efficiency/data?select=Sleep_Efficiency.csv). Задачей является определение качества сна по определенным параметрам.<br /> В результате были получены следующие результаты (для залачи классификаации укзана метрика accuracy, для задачи регрессии MSE):
<table>
    <tr>
        <th rowspan="1">Алгоритм</th>
        <th>Задача</th>
        <th>Бейзлайн</th>
        <th>Улучшенный бейзлайн</th>
        <th>Самостоятельная имплементация алгоритма</th>
    </tr>
    <tr>
        <td rowspan="2">KNN</td>
        <td>классификация</td>
        <td>0.625</td>
        <td>0.655</td>
        <td>0.59</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>0.0033</td>
        <td>0.0032</td>
        <td>0.0042</td>
    </tr>
    <tr>
        <td rowspan="2">Линейные модели</td>
        <td>классификация</td>
        <td>0.675</td>
        <td>0.675</td>
        <td>0.675</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>0.2263</td>
        <td>0.2212</td>
        <td>0.0059</td>
    </tr>
    <tr>
        <td rowspan="2">Решающее дерево</td>
        <td>классификация</td>
        <td>0.52</td>
        <td>0.665</td>
        <td>0.675</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>0.0065</td>
        <td>0.0028</td>
        <td>0.0035</td>
    </tr>
    <tr>
        <td rowspan="2">Случайный лес</td>
        <td>классификация</td>
        <td>0.655</td>
        <td>0.665</td>
        <td>0.675</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>0.0028</td>
        <td>0.0025</td>
        <td>0.0034</td>
    </tr>
    <tr>
        <td rowspan="2">Градиентный бустинг</td>
        <td>классификация</td>
        <td>0.63</td>
        <td>0.675</td>
        <td>0.675</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>0.0027</td>
        <td>0.0025</td>
        <td>0.0027</td>
    </tr>
</table>

В результате можно сказать, что в задаче классификации все алгоритмы, за исключением KNN, показали результат в 0.675, а KNN - 0.655. Для задачи регрессии лучшим оказался алгоритм градиентного бустинга, а худшим - алгоритм линейной регрессии. 
